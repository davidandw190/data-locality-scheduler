apiVersion: v1
kind: ConfigMap
metadata:
  name: streaming-test
  namespace: data-locality-scheduler
data:
  stream-processor.py: |
    import os
    import time
    import socket
    import json

    node_name = os.environ.get("NODE_NAME", "unknown")
    stream_type = os.environ.get("STREAM_TYPE", "unknown")
    region = os.environ.get("NODE_REGION", "unknown")

    print(f"Processing {stream_type} stream on node: {node_name} in region: {region}")
    print(f"Hostname: {socket.gethostname()}")

    # Simulate continuous stream processing
    print(f"Starting {stream_type} stream processing...")
    time.sleep(3600)
---
apiVersion: v1
kind: Pod
metadata:
  name: edge-stream-ingestor
  namespace: data-locality-scheduler
  annotations:
    data.scheduler.thesis/input-1: "edge-bucket/live-stream.bin,10485760,2,5,binary"
    data.scheduler.thesis/output-1: "pipeline-data/processed-stream.json,5242880,0,4,json"
    scheduler.thesis/data-intensive: "true"
    scheduler.thesis/prefer-edge: "true"
    scheduler.thesis/prefer-region: "region-1"
spec:
  schedulerName: data-locality-scheduler
  containers:
  - name: stream-ingestor
    image: python:3.11
    command: [ "python", "/code/stream-processor.py" ]
    env:
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: NODE_REGION
      valueFrom:
        fieldRef:
          fieldPath: metadata.labels['topology.kubernetes.io/region']
    - name: STREAM_TYPE
      value: "sensor-data-ingest"
    volumeMounts:
    - name: code
      mountPath: /code
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
      limits:
        memory: "512Mi"
        cpu: "400m"
  volumes:
  - name: code
    configMap:
      name: streaming-test
  restartPolicy: Never
---
apiVersion: v1
kind: Pod
metadata:
  name: stream-analyzer
  namespace: data-locality-scheduler
  annotations:
    data.scheduler.thesis/input-1: "pipeline-data/processed-stream.json,5242880,10,4,json"
    data.scheduler.thesis/output-1: "analytics/stream-analysis.json,1048576,0,2,json"
    scheduler.thesis/prefer-cloud: "true"
spec:
  schedulerName: data-locality-scheduler
  containers:
  - name: analyzer
    image: python:3.11
    command: [ "python", "/code/stream-processor.py" ]
    env:
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: NODE_REGION
      valueFrom:
        fieldRef:
          fieldPath: metadata.labels['topology.kubernetes.io/region']
    - name: STREAM_TYPE
      value: "real-time-analysis"
    volumeMounts:
    - name: code
      mountPath: /code
    resources:
      requests:
        memory: "1Gi"
        cpu: "500m"
      limits:
        memory: "2Gi"
        cpu: "1"
  volumes:
  - name: code
    configMap:
      name: streaming-test
  restartPolicy: Never
