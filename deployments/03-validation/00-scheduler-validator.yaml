apiVersion: v1
kind: Pod
metadata:
  name: scheduler-analysis
  namespace: data-locality-scheduler
spec:
  containers:
  - name: analyzer
    image: bitnami/kubectl:latest
    command: [ "/bin/bash", "-c" ]
    args:
    - |
      # 1. Check node topology and capabilities
      echo -e "\n1. Node Topology Information:"
      for node in $(kubectl get nodes -o jsonpath='{.items[*].metadata.name}'); do
        echo -e "\nNode: $node"
        NODE_TYPE=$(kubectl get node $node -o jsonpath='{.metadata.labels.node-capability/node-type}')
        REGION=$(kubectl get node $node -o jsonpath='{.metadata.labels.topology\.kubernetes\.io/region}')
        ZONE=$(kubectl get node $node -o jsonpath='{.metadata.labels.topology\.kubernetes\.io/zone}')
        echo "Type: $NODE_TYPE, Region: $REGION, Zone: $ZONE"
      done

      # 2. Storage placement verification
      echo -e "\n2. Storage Service Placement:"
      kubectl get pods -l 'app in (minio,minio-edge)' -n data-locality-scheduler -o custom-columns=NAME:.metadata.name,NODE:.spec.nodeName,STATUS:.status.phase

      # 3. Basic test workloads
      echo -e "\n3. Basic Test Workload Placement:"
      for pod in data-consumer-pod edge-preferring-workload cloud-preferring-workload region2-workload region1-to-region2-transfer; do
        if ! kubectl get pod $pod -n data-locality-scheduler &>/dev/null; then
          echo "Pod $pod not found, skipping"
          continue
        fi
        
        POD_NODE=$(kubectl get pod $pod -n data-locality-scheduler -o jsonpath='{.spec.nodeName}')
        POD_ANNOTATIONS=$(kubectl get pod $pod -n data-locality-scheduler -o json | jq -r '.metadata.annotations | with_entries(select(.key | startswith("data.scheduler") or startswith("scheduler")))')
        NODE_TYPE=$(kubectl get node $POD_NODE -o jsonpath='{.metadata.labels.node-capability/node-type}')
        REGION=$(kubectl get node $POD_NODE -o jsonpath='{.metadata.labels.topology\.kubernetes\.io/region}')
        ZONE=$(kubectl get node $POD_NODE -o jsonpath='{.metadata.labels.topology\.kubernetes\.io/zone}')
        
        echo -e "\nPod: $pod"
        echo "Scheduled on: $POD_NODE (Type: $NODE_TYPE, Region: $REGION, Zone: $ZONE)"
        echo "Pod annotations: $POD_ANNOTATIONS"
        
        # Check specific behavior based on pod type
        if [[ "$pod" == "edge-preferring-workload" ]]; then
          if [[ "$NODE_TYPE" == "edge" ]]; then
            echo "‚úÖ Edge preference honored"
          else
            echo "‚ùå Edge preference NOT honored"
          fi
        elif [[ "$pod" == "cloud-preferring-workload" ]]; then
          if [[ "$NODE_TYPE" == "cloud" ]]; then
            echo "‚úÖ Cloud preference honored"
          else
            echo "‚ùå Cloud preference NOT honored"
          fi
        elif [[ "$pod" == "region2-workload" ]] && [[ $(echo "$POD_ANNOTATIONS" | grep -c "prefer-region.*region-2") -gt 0 ]]; then
          if [[ "$REGION" == "region-2" ]]; then
            echo "‚úÖ Region preference honored"
          else
            echo "‚ùå Region preference NOT honored"
          fi
        fi
      done

      # 4. ETL Pipeline Workload Analysis
      echo -e "\n4. ETL Pipeline Workload Analysis:"
      for pod in data-extract data-transform data-load; do
        if ! kubectl get pod $pod -n data-locality-scheduler &>/dev/null; then
          echo "Pipeline pod $pod not found, skipping"
          continue
        fi
        
        POD_NODE=$(kubectl get pod $pod -n data-locality-scheduler -o jsonpath='{.spec.nodeName}')
        NODE_TYPE=$(kubectl get node $POD_NODE -o jsonpath='{.metadata.labels.node-capability/node-type}')
        REGION=$(kubectl get node $POD_NODE -o jsonpath='{.metadata.labels.topology\.kubernetes\.io/region}')
        
        echo -e "\nPipeline Stage: $pod"
        echo "Scheduled on: $POD_NODE (Type: $NODE_TYPE, Region: $REGION)"
      done

      # Check pipeline locality
      if kubectl get pod data-extract -n data-locality-scheduler &>/dev/null && \
         kubectl get pod data-transform -n data-locality-scheduler &>/dev/null; then
         
        EXTRACT_NODE=$(kubectl get pod data-extract -n data-locality-scheduler -o jsonpath='{.spec.nodeName}')
        TRANSFORM_NODE=$(kubectl get pod data-transform -n data-locality-scheduler -o jsonpath='{.spec.nodeName}')
        
        if [[ "$EXTRACT_NODE" == "$TRANSFORM_NODE" ]]; then
          echo "‚úÖ OPTIMAL PIPELINE LOCALITY: Extract and Transform stages on same node"
        else
          EXTRACT_REGION=$(kubectl get node $EXTRACT_NODE -o jsonpath='{.metadata.labels.topology\.kubernetes\.io/region}')
          TRANSFORM_REGION=$(kubectl get node $TRANSFORM_NODE -o jsonpath='{.metadata.labels.topology\.kubernetes\.io/region}')
          
          if [[ "$EXTRACT_REGION" == "$TRANSFORM_REGION" ]]; then
            echo "üëç GOOD PIPELINE LOCALITY: Extract and Transform stages in same region"
          else
            echo "‚ö†Ô∏è SUB-OPTIMAL PIPELINE LOCALITY: Extract and Transform stages in different regions"
          fi
        fi
      fi

      if kubectl get pod data-transform -n data-locality-scheduler &>/dev/null && \
         kubectl get pod data-load -n data-locality-scheduler &>/dev/null; then
         
        TRANSFORM_NODE=$(kubectl get pod data-transform -n data-locality-scheduler -o jsonpath='{.spec.nodeName}')
        LOAD_NODE=$(kubectl get pod data-load -n data-locality-scheduler -o jsonpath='{.spec.nodeName}')
        LOAD_NODE_TYPE=$(kubectl get node $LOAD_NODE -o jsonpath='{.metadata.labels.node-capability/node-type}')
        
        if [[ "$TRANSFORM_NODE" == "$LOAD_NODE" ]]; then
          echo "‚úÖ OPTIMAL PIPELINE LOCALITY: Transform and Load stages on same node"
        else
          if [[ "$LOAD_NODE_TYPE" == "cloud" ]]; then
            echo "‚úÖ LOAD PREFERENCE HONORED: Final stage properly placed on cloud node"
          else
            echo "‚ùå LOAD PREFERENCE NOT HONORED: Final stage should be on cloud node"
          fi
        fi
      fi

      # 5. Multi-Source Aggregation Analysis
      echo -e "\n5. Multi-Source Aggregation Analysis:"
      for pod in edge-source-aggregator multi-region-aggregator; do
        if ! kubectl get pod $pod -n data-locality-scheduler &>/dev/null; then
          echo "Aggregator pod $pod not found, skipping"
          continue
        fi
        
        POD_NODE=$(kubectl get pod $pod -n data-locality-scheduler -o jsonpath='{.spec.nodeName}')
        NODE_TYPE=$(kubectl get node $POD_NODE -o jsonpath='{.metadata.labels.node-capability/node-type}')
        REGION=$(kubectl get node $POD_NODE -o jsonpath='{.metadata.labels.topology\.kubernetes\.io/region}')
        
        echo -e "\nAggregator: $pod"
        echo "Scheduled on: $POD_NODE (Type: $NODE_TYPE, Region: $REGION)"
        
        if [[ "$pod" == "edge-source-aggregator" ]]; then
          if [[ "$NODE_TYPE" == "edge" ]]; then
            echo "‚úÖ Edge preference honored for edge data aggregation"
          else
            echo "‚ùå Edge preference NOT honored for edge data aggregation"
          fi
        elif [[ "$pod" == "multi-region-aggregator" ]]; then
          if [[ "$NODE_TYPE" == "cloud" ]]; then
            echo "‚úÖ Cloud preference honored for multi-region aggregation"
          else
            echo "‚ùå Cloud preference NOT honored for multi-region aggregation"
          fi
        fi
      done

      # 6. Resource vs Locality Tradeoff Analysis
      echo -e "\n6. Resource vs Locality Tradeoff Analysis:"
      for pod in compute-intensive-processor balanced-data-processor memory-intensive-processor; do
        if ! kubectl get pod $pod -n data-locality-scheduler &>/dev/null; then
          echo "Processor pod $pod not found, skipping"
          continue
        fi
        
        POD_NODE=$(kubectl get pod $pod -n data-locality-scheduler -o jsonpath='{.spec.nodeName}')
        NODE_TYPE=$(kubectl get node $POD_NODE -o jsonpath='{.metadata.labels.node-capability/node-type}')
        REGION=$(kubectl get node $POD_NODE -o jsonpath='{.metadata.labels.topology\.kubernetes\.io/region}')
        
        echo -e "\nProcessor: $pod"
        echo "Scheduled on: $POD_NODE (Type: $NODE_TYPE, Region: $REGION)"
        
        case "$pod" in
          compute-intensive-processor)
            if [[ "$NODE_TYPE" == "cloud" ]]; then
              echo "‚úÖ CORRECTLY PLACED: Compute-intensive workload on cloud node"
            else
              echo "‚ö†Ô∏è UNEXPECTED PLACEMENT: Compute-intensive workload should be on cloud node"
            fi
            ;;
          balanced-data-processor)
            # Check if this pod was placed near its data source (region-2)
            if [[ "$REGION" == "region-2" ]]; then
              echo "‚úÖ CORRECTLY PLACED: Data-intensive workload near data source"
            else
              echo "‚ö†Ô∏è SUB-OPTIMAL PLACEMENT: Data workload not near its data source"
            fi
            ;;
          memory-intensive-processor)
            if [[ "$NODE_TYPE" == "edge" ]]; then
              echo "‚úÖ EDGE PREFERENCE HONORED: Memory-intensive workload on edge"
            else
              echo "‚ùå EDGE PREFERENCE NOT HONORED: Workload should be on edge node"
            fi
            ;;
        esac
      done

      # 7. Data Migration Analysis
      echo -e "\n7. Data Migration Analysis:"
      for pod in large-data-migration incremental-data-sync; do
        if ! kubectl get pod $pod -n data-locality-scheduler &>/dev/null; then
          echo "Migration pod $pod not found, skipping"
          continue
        fi
        
        POD_NODE=$(kubectl get pod $pod -n data-locality-scheduler -o jsonpath='{.spec.nodeName}')
        NODE_TYPE=$(kubectl get node $POD_NODE -o jsonpath='{.metadata.labels.node-capability/node-type}')
        REGION=$(kubectl get node $POD_NODE -o jsonpath='{.metadata.labels.topology\.kubernetes\.io/region}')
        
        echo -e "\nMigration Job: $pod"
        echo "Scheduled on: $POD_NODE (Type: $NODE_TYPE, Region: $REGION)"
        
        case "$pod" in
          large-data-migration)
            if [[ "$REGION" == "region-1" ]]; then
              echo "‚úÖ CORRECTLY PLACED: Large data migration near source data"
            else
              echo "‚ùå POORLY PLACED: Large migration should be near source data"
            fi
            ;;
          incremental-data-sync)
            if [[ "$REGION" == "region-2" ]]; then
              echo "‚úÖ CORRECTLY PLACED: Incremental sync near target location"
            else
              echo "‚ùå POORLY PLACED: Incremental sync should be near target location"
            fi
            ;;
        esac
      done

      # 8. Edge Streaming Analysis
      echo -e "\n8. Edge Streaming Analysis:"
      for pod in edge-stream-ingestor stream-analyzer; do
        if ! kubectl get pod $pod -n data-locality-scheduler &>/dev/null; then
          echo "Streaming pod $pod not found, skipping"
          continue
        fi
        
        POD_NODE=$(kubectl get pod $pod -n data-locality-scheduler -o jsonpath='{.spec.nodeName}')
        NODE_TYPE=$(kubectl get node $POD_NODE -o jsonpath='{.metadata.labels.node-capability/node-type}')
        REGION=$(kubectl get node $POD_NODE -o jsonpath='{.metadata.labels.topology\.kubernetes\.io/region}')
        
        echo -e "\nStreaming Component: $pod"
        echo "Scheduled on: $POD_NODE (Type: $NODE_TYPE, Region: $REGION)"
        
        case "$pod" in
          edge-stream-ingestor)
            if [[ "$NODE_TYPE" == "edge" ]]; then
              echo "‚úÖ CORRECTLY PLACED: Stream ingestor on edge node"
            else
              echo "‚ùå POORLY PLACED: Stream ingestor should be on edge node"
            fi
            ;;
          stream-analyzer)
            if [[ "$NODE_TYPE" == "cloud" ]]; then
              echo "‚úÖ CORRECTLY PLACED: Stream analyzer on cloud node"
            else
              echo "‚ùå POORLY PLACED: Stream analyzer should be on cloud node"
            fi
            ;;
        esac
      done

      # 9. Overall Scheduler Performance
      echo -e "\n9. Overall Scheduler Performance Assessment:"

      TOTAL_PODS=$(kubectl get pods -n data-locality-scheduler --field-selector=status.phase=Running | grep -v "node-capability-daemon" | wc -l)

      echo "Total managed workloads: $TOTAL_PODS"
      echo "Data locality checks completed"
    resources:
      requests:
        cpu: "250m"
        memory: "128Mi"
      limits:
        cpu: "500m"
        memory: "256Mi"
  restartPolicy: Never
  serviceAccountName: data-locality-scheduler
