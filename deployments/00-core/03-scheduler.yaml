apiVersion: v1
kind: ConfigMap
metadata:
  name: data-locality-scheduler-config
  namespace: data-locality-scheduler
data:
  scheduler-config.yaml: |
    schedulerName: "data-locality-scheduler"
    podQueueSize: 100
    healthServerPort: 8080
    refreshInterval: "5m"
    enableMockData: false

    # Filtering options
    percentageOfNodesToScore: 100
    minFeasibleNodesToFind: 100
    maxFailedAttempts: 5

    # Caching options
    resourceCacheEnabled: true
    resourceCacheExpiration: "30s"
    storageCacheExpiration: "5m"

    resourceWeight: 0.2
    nodeAffinityWeight: 0.1
    nodeTypeWeight: 0.2
    capabilitiesWeight: 0.1
    dataLocalityWeight: 0.4

    # Data-intensive weights
    dataIntensiveResourceWeight: 0.1
    dataIntensiveNodeAffinityWeight: 0.1
    dataIntensiveNodeTypeWeight: 0.1
    dataIntensiveCapabilitiesWeight: 0.1
    dataIntensiveDataLocalityWeight: 0.6

    # Compute-intensive weights
    computeIntensiveResourceWeight: 0.5
    computeIntensiveNodeAffinityWeight: 0.2
    computeIntensiveNodeTypeWeight: 0.1
    computeIntensiveCapabilitiesWeight: 0.1
    computeIntensiveDataLocalityWeight: 0.1

    # Bandwidth settings in bytes/second
    localBandwidth: 1000000000 # 1 GB/s
    sameZoneBandwidth: 600000000 # 600 MB/s
    sameRegionBandwidth: 200000000 # 200 MB/s
    crossRegionBandwidth: 50000000 # 50 MB/s
    edgeCloudBandwidth: 25000000 # 25 MB/s

    # Latency settings in milliseconds
    localLatency: 0.1
    sameZoneLatency: 1.0
    sameRegionLatency: 5.0
    crossRegionLatency: 30.0
    edgeCloudLatency: 40.0

    # Resource allocation defaults
    defaultCPURequest: 100 # 100m
    defaultMemoryRequest: 209715200 # 200Mi

    # Node scoring options
    minResourceScore: 0
    maxResourceScore: 100
    defaultScore: 50

    # Metrics options
    detailedMetrics: true
    metricsHistorySize: 100  # Number of scheduling decisions to keep in memory

    # Debug options
    verboseLogging: true
    enableProfiling: false
    enableAPIEndpoint: true
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: data-locality-scheduler
  namespace: data-locality-scheduler
  labels:
    app: data-locality-scheduler
spec:
  replicas: 1
  selector:
    matchLabels:
      app: data-locality-scheduler
  template:
    metadata:
      labels:
        app: data-locality-scheduler
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: data-locality-scheduler
      containers:
      - name: scheduler
        image: davidandw190/data-locality-scheduler:latest
        imagePullPolicy: Always
        args:
        - "--config=/etc/scheduler/scheduler-config.yaml"
        - "--verbose=true"
        - "--detailed-metrics=true"
        env:
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        ports:
        - containerPort: 8080
          name: http
        readinessProbe:
          httpGet:
            path: /readyz
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 2
          successThreshold: 1
          failureThreshold: 3
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          initialDelaySeconds: 15
          periodSeconds: 20
          timeoutSeconds: 2
          successThreshold: 1
          failureThreshold: 3
        resources:
          requests:
            cpu: 200m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 1Gi
        volumeMounts:
        - name: config-volume
          mountPath: /etc/scheduler
        securityContext:
          runAsNonRoot: true
          runAsUser: 1000
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          seccompProfile:
            type: RuntimeDefault
      volumes:
      - name: config-volume
        configMap:
          name: data-locality-scheduler-config
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 10
            preference:
              matchExpressions:
              - key: node-capability/node-type
                operator: In
                values:
                - cloud
      tolerations:
      - key: "node-role.kubernetes.io/master"
        operator: "Exists"
        effect: "NoSchedule"
      - key: "node-role.kubernetes.io/control-plane"
        operator: "Exists"
        effect: "NoSchedule"
---
apiVersion: v1
kind: Service
metadata:
  name: data-locality-scheduler
  namespace: data-locality-scheduler
  labels:
    app: data-locality-scheduler
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8080"
    prometheus.io/path: "/metrics"
    description: "Service exposing health check, metrics, and API endpoints for the scheduler"
spec:
  selector:
    app: data-locality-scheduler
  ports:
  - port: 8080
    targetPort: 8080
    name: http
  type: ClusterIP
