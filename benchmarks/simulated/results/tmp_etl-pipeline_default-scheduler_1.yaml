apiVersion: v1
kind: Pod
metadata:
  annotations:
    benchmark.thesis/iteration: '1'
    benchmark.thesis/run-id: abab1ff2
    benchmark.thesis/scheduler: default-scheduler
    benchmark.thesis/workload: etl-pipeline
    data.scheduler.thesis/input-1: region1-bucket/raw-data-batch.csv,104857600,5,9,csv
    data.scheduler.thesis/output-1: intermediate/extracted-region1.parquet,52428800,0,8,parquet
    scheduler.thesis/data-intensive: 'true'
    scheduler.thesis/prefer-edge: 'true'
    scheduler.thesis/prefer-region: region-1
  labels:
    benchmark-run-id: abab1ff2
    iteration: '1'
    scheduler: defaultscheduler
    stage: extract
    workload: etl-pipeline
  name: etl-extractor-region1-abab1ff2-1
  namespace: scheduler-benchmark
spec:
  containers:
  - command:
    - python
    - /app/simulator.py
    env:
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: WORKLOAD_TYPE
      value: etl-extraction
    - name: WORKLOAD_ACTION
      value: extract
    - name: WORKLOAD_INTENSITY
      value: medium
    - name: WORKLOAD_DURATION
      value: '50'
    - name: BENCHMARK_RUN_ID
      value: abab1ff2
    - name: WORKLOAD_NAME
      value: etl-pipeline
    - name: SCHEDULER_NAME
      value: default-scheduler
    - name: ITERATION
      value: '1'
    - name: WORKLOAD_DURATION
      value: '60'
    - name: DATA_SCHEDULER_THESIS_INPUT_1
      value: region1-bucket/raw-data-batch.csv,104857600,5,9,csv
    - name: DATA_SCHEDULER_THESIS_OUTPUT_1
      value: intermediate/extracted-region1.parquet,52428800,0,8,parquet
    image: davidandw190/workload-sim:latest
    name: etl-extractor
    resources:
      limits:
        cpu: 800m
        memory: 1Gi
      requests:
        cpu: 400m
        memory: 512Mi
  restartPolicy: Never
  schedulerName: default-scheduler
  tolerations:
  - effect: NoSchedule
    key: node-role.kubernetes.io/control-plane
    operator: Exists
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
    operator: Exists
---
apiVersion: v1
kind: Pod
metadata:
  annotations:
    benchmark.thesis/iteration: '1'
    benchmark.thesis/run-id: abab1ff2
    benchmark.thesis/scheduler: default-scheduler
    benchmark.thesis/workload: etl-pipeline
    data.scheduler.thesis/input-1: region2-bucket/raw-data-batch.csv,104857600,5,9,csv
    data.scheduler.thesis/output-1: intermediate/extracted-region2.parquet,52428800,0,8,parquet
    scheduler.thesis/data-intensive: 'true'
    scheduler.thesis/prefer-edge: 'true'
    scheduler.thesis/prefer-region: region-2
  labels:
    benchmark-run-id: abab1ff2
    iteration: '1'
    scheduler: defaultscheduler
    stage: extract
    workload: etl-pipeline
  name: etl-extractor-region2-abab1ff2-1
  namespace: scheduler-benchmark
spec:
  containers:
  - command:
    - python
    - /app/simulator.py
    env:
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: WORKLOAD_TYPE
      value: etl-extraction
    - name: WORKLOAD_ACTION
      value: extract
    - name: WORKLOAD_INTENSITY
      value: medium
    - name: WORKLOAD_DURATION
      value: '50'
    - name: BENCHMARK_RUN_ID
      value: abab1ff2
    - name: WORKLOAD_NAME
      value: etl-pipeline
    - name: SCHEDULER_NAME
      value: default-scheduler
    - name: ITERATION
      value: '1'
    - name: WORKLOAD_DURATION
      value: '60'
    - name: DATA_SCHEDULER_THESIS_INPUT_1
      value: region2-bucket/raw-data-batch.csv,104857600,5,9,csv
    - name: DATA_SCHEDULER_THESIS_OUTPUT_1
      value: intermediate/extracted-region2.parquet,52428800,0,8,parquet
    image: davidandw190/workload-sim:latest
    name: etl-extractor
    resources:
      limits:
        cpu: 800m
        memory: 1Gi
      requests:
        cpu: 400m
        memory: 512Mi
  restartPolicy: Never
  schedulerName: default-scheduler
  tolerations:
  - effect: NoSchedule
    key: node-role.kubernetes.io/control-plane
    operator: Exists
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
    operator: Exists
---
apiVersion: v1
kind: Pod
metadata:
  annotations:
    benchmark.thesis/iteration: '1'
    benchmark.thesis/run-id: abab1ff2
    benchmark.thesis/scheduler: default-scheduler
    benchmark.thesis/workload: etl-pipeline
    data.scheduler.thesis/input-1: intermediate/extracted-region1.parquet,52428800,15,8,parquet
    data.scheduler.thesis/input-2: intermediate/extracted-region2.parquet,52428800,15,8,parquet
    data.scheduler.thesis/input-3: datasets/reference-data.json,20971520,10,7,json
    data.scheduler.thesis/output-1: intermediate/transformed-data.parquet,83886080,0,7,parquet
    scheduler.thesis/compute-intensive: 'true'
    scheduler.thesis/data-intensive: 'true'
    scheduler.thesis/memory-intensive: 'true'
    scheduler.thesis/prefer-cloud: 'true'
  labels:
    benchmark-run-id: abab1ff2
    iteration: '1'
    scheduler: defaultscheduler
    stage: transform
    workload: etl-pipeline
  name: etl-transformer-abab1ff2-1
  namespace: scheduler-benchmark
spec:
  containers:
  - command:
    - python
    - /app/simulator.py
    env:
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: WORKLOAD_TYPE
      value: etl-transformation
    - name: WORKLOAD_ACTION
      value: transform
    - name: WORKLOAD_INTENSITY
      value: very-high
    - name: WORKLOAD_DURATION
      value: '90'
    - name: BENCHMARK_RUN_ID
      value: abab1ff2
    - name: WORKLOAD_NAME
      value: etl-pipeline
    - name: SCHEDULER_NAME
      value: default-scheduler
    - name: ITERATION
      value: '1'
    - name: WORKLOAD_DURATION
      value: '60'
    - name: DATA_SCHEDULER_THESIS_INPUT_1
      value: intermediate/extracted-region1.parquet,52428800,15,8,parquet
    - name: DATA_SCHEDULER_THESIS_INPUT_2
      value: intermediate/extracted-region2.parquet,52428800,15,8,parquet
    - name: DATA_SCHEDULER_THESIS_INPUT_3
      value: datasets/reference-data.json,20971520,10,7,json
    - name: DATA_SCHEDULER_THESIS_OUTPUT_1
      value: intermediate/transformed-data.parquet,83886080,0,7,parquet
    image: davidandw190/workload-sim:latest
    name: etl-transformer
    resources:
      limits:
        cpu: 3000m
        memory: 4Gi
      requests:
        cpu: 1500m
        memory: 2Gi
  restartPolicy: Never
  schedulerName: default-scheduler
  tolerations:
  - effect: NoSchedule
    key: node-role.kubernetes.io/control-plane
    operator: Exists
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
    operator: Exists
---
apiVersion: v1
kind: Pod
metadata:
  annotations:
    benchmark.thesis/iteration: '1'
    benchmark.thesis/run-id: abab1ff2
    benchmark.thesis/scheduler: default-scheduler
    benchmark.thesis/workload: etl-pipeline
    data.scheduler.thesis/input-1: intermediate/transformed-data.parquet,83886080,10,7,parquet
    data.scheduler.thesis/output-1: datasets/warehouse-data.parquet,83886080,0,7,parquet
    data.scheduler.thesis/output-2: results/etl-summary.json,1048576,0,6,json
    scheduler.thesis/data-intensive: 'true'
    scheduler.thesis/prefer-cloud: 'true'
  labels:
    benchmark-run-id: abab1ff2
    iteration: '1'
    scheduler: defaultscheduler
    stage: load
    workload: etl-pipeline
  name: etl-loader-warehouse-abab1ff2-1
  namespace: scheduler-benchmark
spec:
  containers:
  - command:
    - python
    - /app/simulator.py
    env:
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: WORKLOAD_TYPE
      value: etl-loading
    - name: WORKLOAD_ACTION
      value: load
    - name: WORKLOAD_INTENSITY
      value: high
    - name: WORKLOAD_DURATION
      value: '60'
    - name: BENCHMARK_RUN_ID
      value: abab1ff2
    - name: WORKLOAD_NAME
      value: etl-pipeline
    - name: SCHEDULER_NAME
      value: default-scheduler
    - name: ITERATION
      value: '1'
    - name: WORKLOAD_DURATION
      value: '60'
    - name: DATA_SCHEDULER_THESIS_INPUT_1
      value: intermediate/transformed-data.parquet,83886080,10,7,parquet
    - name: DATA_SCHEDULER_THESIS_OUTPUT_1
      value: datasets/warehouse-data.parquet,83886080,0,7,parquet
    - name: DATA_SCHEDULER_THESIS_OUTPUT_2
      value: results/etl-summary.json,1048576,0,6,json
    image: davidandw190/workload-sim:latest
    name: etl-loader
    resources:
      limits:
        cpu: 1200m
        memory: 2Gi
      requests:
        cpu: 600m
        memory: 1Gi
  restartPolicy: Never
  schedulerName: default-scheduler
  tolerations:
  - effect: NoSchedule
    key: node-role.kubernetes.io/control-plane
    operator: Exists
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
    operator: Exists
---
apiVersion: v1
kind: Pod
metadata:
  annotations:
    benchmark.thesis/iteration: '1'
    benchmark.thesis/run-id: abab1ff2
    benchmark.thesis/scheduler: default-scheduler
    benchmark.thesis/workload: etl-pipeline
    data.scheduler.thesis/input-1: intermediate/transformed-data.parquet,83886080,25,7,parquet
    data.scheduler.thesis/output-1: region1-bucket/processed-data.parquet,41943040,0,8,parquet
    scheduler.thesis/data-intensive: 'true'
    scheduler.thesis/prefer-edge: 'true'
    scheduler.thesis/prefer-region: region-1
  labels:
    benchmark-run-id: abab1ff2
    iteration: '1'
    scheduler: defaultscheduler
    stage: load
    workload: etl-pipeline
  name: etl-loader-edge1-abab1ff2-1
  namespace: scheduler-benchmark
spec:
  containers:
  - command:
    - python
    - /app/simulator.py
    env:
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: WORKLOAD_TYPE
      value: etl-edge-loading
    - name: WORKLOAD_ACTION
      value: load
    - name: WORKLOAD_INTENSITY
      value: medium
    - name: WORKLOAD_DURATION
      value: '45'
    - name: BENCHMARK_RUN_ID
      value: abab1ff2
    - name: WORKLOAD_NAME
      value: etl-pipeline
    - name: SCHEDULER_NAME
      value: default-scheduler
    - name: ITERATION
      value: '1'
    - name: WORKLOAD_DURATION
      value: '60'
    - name: DATA_SCHEDULER_THESIS_INPUT_1
      value: intermediate/transformed-data.parquet,83886080,25,7,parquet
    - name: DATA_SCHEDULER_THESIS_OUTPUT_1
      value: region1-bucket/processed-data.parquet,41943040,0,8,parquet
    image: davidandw190/workload-sim:latest
    name: etl-edge-loader
    resources:
      limits:
        cpu: 800m
        memory: 1Gi
      requests:
        cpu: 400m
        memory: 512Mi
  restartPolicy: Never
  schedulerName: default-scheduler
  tolerations:
  - effect: NoSchedule
    key: node-role.kubernetes.io/control-plane
    operator: Exists
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
    operator: Exists
---
apiVersion: v1
kind: Pod
metadata:
  annotations:
    benchmark.thesis/iteration: '1'
    benchmark.thesis/run-id: abab1ff2
    benchmark.thesis/scheduler: default-scheduler
    benchmark.thesis/workload: etl-pipeline
    data.scheduler.thesis/input-1: intermediate/transformed-data.parquet,83886080,25,7,parquet
    data.scheduler.thesis/output-1: region2-bucket/processed-data.parquet,41943040,0,8,parquet
    scheduler.thesis/data-intensive: 'true'
    scheduler.thesis/prefer-edge: 'true'
    scheduler.thesis/prefer-region: region-2
  labels:
    benchmark-run-id: abab1ff2
    iteration: '1'
    scheduler: defaultscheduler
    stage: load
    workload: etl-pipeline
  name: etl-loader-edge2-abab1ff2-1
  namespace: scheduler-benchmark
spec:
  containers:
  - command:
    - python
    - /app/simulator.py
    env:
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: WORKLOAD_TYPE
      value: etl-edge-loading
    - name: WORKLOAD_ACTION
      value: load
    - name: WORKLOAD_INTENSITY
      value: medium
    - name: WORKLOAD_DURATION
      value: '45'
    - name: BENCHMARK_RUN_ID
      value: abab1ff2
    - name: WORKLOAD_NAME
      value: etl-pipeline
    - name: SCHEDULER_NAME
      value: default-scheduler
    - name: ITERATION
      value: '1'
    - name: WORKLOAD_DURATION
      value: '60'
    - name: DATA_SCHEDULER_THESIS_INPUT_1
      value: intermediate/transformed-data.parquet,83886080,25,7,parquet
    - name: DATA_SCHEDULER_THESIS_OUTPUT_1
      value: region2-bucket/processed-data.parquet,41943040,0,8,parquet
    image: davidandw190/workload-sim:latest
    name: etl-edge-loader
    resources:
      limits:
        cpu: 800m
        memory: 1Gi
      requests:
        cpu: 400m
        memory: 512Mi
  restartPolicy: Never
  schedulerName: default-scheduler
  tolerations:
  - effect: NoSchedule
    key: node-role.kubernetes.io/control-plane
    operator: Exists
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
    operator: Exists
